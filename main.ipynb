{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from cleaning import sessioninfo, scores, create\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import project_functions\n",
    "from project_functions import decompose, drop_stubs, make_data_rectangular\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pymc as pm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import math\n",
    "import torch\n",
    "\n",
    "#TODO: Remove project_functions, cleaning, and CAPS.py and other stuff that isn't used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_VAL = 0.5\n",
    "#Gamme distributions can't actually take 0 values with nonzero probability, so Bayesian credible intervals require that all 0 errors be replaced with something else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering and processing raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up options for data cleaning\n",
    "# besides data path root folders, copied from code by Seth Peacock, who wrote the cleaning code (except for a few tweaks)\n",
    "data_path_old = [\"..\"]\n",
    "data_path_new = [\"..\", \"2018-2023\"]\n",
    "recent_dict = {'Within the last 2 weeks': 1, 'Within the last month': 1,\n",
    "        'Within the last year': 1, 'Within the last 1-5 years': 0,\n",
    "        'More than 5 years ago': 0, 'Never': 0, '<No Response>': 0}\n",
    "\n",
    "session_arg = dict(unique_therapist=True, # unique therapist\n",
    "                   intake_dif=False,\n",
    "                   min_appoint=1,\n",
    "                   max_diff_between_apps=180)\n",
    "\n",
    "match_arg = dict(recent_dict=recent_dict)\n",
    "\n",
    "imput_arg = dict(na_cutoff=1,\n",
    "                 n_components=10)\n",
    "\n",
    "scores_arg = dict(days_before=30, \n",
    "                  days_after=7)\n",
    "\n",
    "filter_arg = dict(cutoff_hi=180, \n",
    "                  cutoff_low=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the non-hidden clients\n",
    "app_hid, patient_info, scores_df = create.get_old_data(data_path_new, data_path_old, data_path_old, hide=True, dataset=\"old\")\n",
    "\n",
    "master_df_1, app_session = sessioninfo.make_session(appoint_data=app_hid, **session_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Link appointment data to patient information\n",
    "master_df_2 = sessioninfo.match_patient_info(master_df=master_df_1, \n",
    "                                                 patient_data=patient_info,\n",
    "                                                 **match_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_2.to_csv('master_df_2_cu002_thesis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Link appointment data to OQ score data\n",
    "app_oq = scores.oq_score(app_session=app_session, scores=scores_df, **scores_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_oq.to_csv('appointment_oq_cu002_thesis.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As above, but with the hidden clients\n",
    "app_hid, patient_info, scores_df = create.get_old_data(data_path_new, data_path_old, data_path_old, hide=False, dataset=\"old\")\n",
    "\n",
    "master_df_1, app_session = sessioninfo.make_session(appoint_data=app_hid, **session_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_2 = sessioninfo.match_patient_info(master_df=master_df_1, \n",
    "                                                 patient_data=patient_info,\n",
    "                                                 **match_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_2.to_csv('master_df_2_cu003_thesis_hiddenClients.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_oq = scores.oq_score(app_session=app_session, scores=scores_df, **scores_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_oq.to_csv('appointment_oq_cu003_thesis_hiddenClients.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make usable for time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appointments_df = pd.read_csv('appointment_oq_cu002_thesis.csv')\n",
    "appointments_df.dropna(inplace=True, subset=['ClientID', 'SessionID', 'CurrentScore', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For redundancy, exclude clients on the list of hidden clients\n",
    "hidden_clients_list = []\n",
    "with open('../ClientsHiddenAway', 'r') as file:\n",
    "    for line in file:\n",
    "        hidden_clients_list.append(int(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_hidden_clients = set(appointments_df['ClientID'].unique())\n",
    "print(len(list(non_hidden_clients)))\n",
    "\n",
    "#Create sets of clients for training and validation\n",
    "train_clients, val_clients = train_test_split(list(non_hidden_clients), test_size=0.25, random_state = 404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(train_clients).intersection(set(val_clients))) == 0\n",
    "\n",
    "#Save train and val clients for future reference\n",
    "with open('local_train_clients.txt', 'w') as file:\n",
    "    for client in train_clients:\n",
    "        file.write(str(client)+'\\n')\n",
    "\n",
    "with open('local_val_clients.txt', 'w') as file:\n",
    "    for client in val_clients:\n",
    "        file.write(str(client)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure that no clients weren't included in part of the split\n",
    "\n",
    "with open('local_train_clients.txt', 'r') as file:\n",
    "    train_lines = file.readlines()\n",
    "train_clients = [int(line.split()[0]) for line in train_lines]\n",
    "\n",
    "with open('local_val_clients.txt', 'r') as file:\n",
    "    val_lines = file.readlines()\n",
    "val_clients = [int(line.split()[0]) for line in val_lines]\n",
    "\n",
    "all_sorted_clients = set(train_clients).union(set(val_clients)).union(set(hidden_clients_list))\n",
    "\n",
    "new_clients = []\n",
    "num_old = 0\n",
    "for client_ID in appointments_df['ClientID']:\n",
    "    if client_ID not in all_sorted_clients and client_ID not in new_clients:\n",
    "        new_clients.append(client_ID)\n",
    "    else:\n",
    "        num_old += 1\n",
    "print(len(new_clients))\n",
    "if len(new_clients) > 0:\n",
    "    new_train_clients, new_val_clients = train_test_split(new_clients, test_size=0.25, random_state = 404)\n",
    "    print(len(new_train_clients))\n",
    "    print(len(new_val_clients))\n",
    "    try:\n",
    "        assert len(set(new_train_clients).intersection(set(new_val_clients)))==0\n",
    "    except:\n",
    "        print(set(new_train_clients).intersection(set(new_val_clients)))\n",
    "        raise\n",
    "    train_clients = train_clients + new_train_clients\n",
    "    val_clients = val_clients + new_val_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(train_clients).intersection(set(val_clients))) == 0\n",
    "\n",
    "\n",
    "#Save updated train and val clients for future reference\n",
    "if len(new_clients) > 0:\n",
    "    with open('local_train_clients.txt', 'w') as file:\n",
    "        for client in train_clients:\n",
    "            file.write(str(client)+'\\n')\n",
    "\n",
    "    with open('local_val_clients.txt', 'w') as file:\n",
    "        for client in val_clients:\n",
    "            file.write(str(client)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make appointments_df into something we can get time series out of\n",
    "appointments_df.rename({'SessionID':'Session', 'CurrentScore': 'OQ'}, inplace=True, axis=1)\n",
    "appointments_df = appointments_df[['ClientID', 'Session', 'OQ', 'Date']].drop_duplicates()\n",
    "appointments_df['Session'] = appointments_df['Session'].astype(int)\n",
    "\n",
    "appointments_df['Date'] = pd.to_datetime(appointments_df['Date'])\n",
    "    # the argument format='ISO8601' was necessary on some machines\n",
    "\n",
    "appointments_df.sort_values(['Session', 'Date'], inplace=True)\n",
    "\n",
    "train_appts = appointments_df.loc[appointments_df['ClientID'].isin(train_clients)].dropna()\n",
    "val_appts = appointments_df.loc[appointments_df['ClientID'].isin(val_clients)].dropna()\n",
    "\n",
    "#This is a list of lists. Each of the inside lists is a time series.\n",
    "OQ_lists = []\n",
    "for df in [train_appts, val_appts]:\n",
    "    OQ_lists.append([list(df[df['Session'] == session]['OQ'].values) for session in df['Session'].unique()])\n",
    "\n",
    "train_OQ_list, val_OQ_list = OQ_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the timeseries data to a pickled file\n",
    "with open('OQ_lists_new.pkl', 'wb') as file:\n",
    "    pickle.Pickler(file=file).dump(OQ_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now do the test data\n",
    "appointments_df_test = pd.read_csv('appointment_oq_cu003_thesis_hiddenClients.csv')\n",
    "appointments_df_test.dropna(inplace=True, subset=['ClientID', 'SessionID', 'CurrentScore', 'Date'])\n",
    "\n",
    "all_sorted_clients = set(train_clients).union(set(val_clients)).union(set(hidden_clients_list))\n",
    "for client_ID in appointments_df_test['ClientID']:\n",
    "    assert client_ID in hidden_clients_list\n",
    "\n",
    "appointments_df_test.rename({'SessionID':'Session', 'CurrentScore': 'OQ'}, inplace=True, axis=1)\n",
    "appointments_df_test = appointments_df_test[['ClientID', 'Session', 'OQ', 'Date']].drop_duplicates()\n",
    "appointments_df_test['Session'] = appointments_df_test['Session'].astype(int)\n",
    "\n",
    "appointments_df_test['Date'] = pd.to_datetime(appointments_df_test['Date'])\n",
    "\n",
    "appointments_df_test.sort_values(['Session', 'Date'], inplace=True)\n",
    "\n",
    "test_OQ_list = [list(appointments_df_test[appointments_df_test['Session'] == session]['OQ'].values) for session in appointments_df_test['Session'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_list_new.pkl', 'wb') as file:\n",
    "    pickle.Pickler(file=file).dump(test_OQ_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Link session numbers to observations for test data\n",
    "test_sessions_list = appointments_df_test['Session'].unique()\n",
    "test_OQ_list = [list(appointments_df_test[appointments_df_test['Session'] == session]['OQ'].values) for session in test_sessions_list]\n",
    "\n",
    "test_rows_list = []\n",
    "\n",
    "for i, OQ_list in enumerate(test_OQ_list):\n",
    "    truncations, nexts = decompose(OQ_list)\n",
    "    for j in range(len(truncations)):\n",
    "        test_rows_list.append({\n",
    "            'Session': test_sessions_list[i],\n",
    "            'Previous': truncations[j],\n",
    "            'Next': nexts[j],\n",
    "            'Num_Steps': len(truncations)\n",
    "        })\n",
    "\n",
    "test_data_df = pd.DataFrame(test_rows_list)\n",
    "with open('test_data_new.pkl', 'wb') as file:\n",
    "    pickle.Pickler(file=file).dump(test_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of a Prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load cleaned data\n",
    "with open('OQ_lists_new.pkl', 'rb') as file:\n",
    "    OQ_lists_new = pickle.Unpickler(file).load()\n",
    "train_OQ_list_new, val_OQ_list_new = OQ_lists_new\n",
    "\n",
    "# Drop stubs\n",
    "train_OQ_list_new = drop_stubs(train_OQ_list_new)\n",
    "val_OQ_list_new = drop_stubs(val_OQ_list_new)\n",
    "\n",
    "\n",
    "val_prevs_list_new = []\n",
    "val_next_list_new = []\n",
    "for timeseries in val_OQ_list_new:\n",
    "    prevs, nexts = decompose(timeseries)\n",
    "    for i in range(len(prevs)):\n",
    "        val_prevs_list_new.append(prevs[i])\n",
    "        val_next_list_new.append(nexts[i])\n",
    "val_next_list_new = np.array(val_next_list_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "indices_to_sample_new = np.random.choice(len(val_prevs_list_new), replace=False, size=50)\n",
    "\n",
    "time_series_list = [val_prevs_list_new[indices_to_sample_new[i]] for i in range(50)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual prediction process is omitted to protect data privacy. The author observed and plotted each of the 50 validation-set time series, recorded his guess for the next value, and after all predictions were made, compared his predictions to the true values to find the following errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_errors = np.array([7,14,16,5,5,9,16,1,6,1,10,11,9,1,17,9,12,12,5,22,4,13,10,2,14,6,1,19,13,3,13,22,7,2,4,1,2,7,8,42,1,6,6,11,5,2,12,1,15,REPLACE_VAL])\n",
    "#Last prediction, 0, replaced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate parameters of priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate bootstrap samples to measure mean and variance empirically\n",
    "def get_bootstrap_sample(bootstrap_n):\n",
    "    indices = np.random.choice(len(abs_errors), size=bootstrap_n, replace=True)\n",
    "    return abs_errors[indices]\n",
    "\n",
    "means = []\n",
    "vars = []\n",
    "np.random.seed(42)\n",
    "for i in range(30):\n",
    "    sample = get_bootstrap_sample(20)\n",
    "    means.append(np.mean(sample))\n",
    "    vars.append(np.var(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_mean = np.mean(means)\n",
    "means_var = np.var(means)\n",
    "\n",
    "#Variance will have a gamma prior, so use the mean and variance of the variance samples to derive alpha and beta (rate)\n",
    "vars_mean = np.mean(vars)\n",
    "vars_var = np.var(vars)\n",
    "vars_b = vars_mean/vars_var\n",
    "vars_a = vars_mean*vars_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(means_mean)\n",
    "print(means_var)\n",
    "print(vars_a)\n",
    "print(vars_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load cleaned test data\n",
    "\n",
    "with open('test_list_new.pkl', 'rb') as file:\n",
    "    test_OQ_list_new = pickle.Unpickler(file).load()\n",
    "\n",
    "test_OQ_list_new = drop_stubs(test_OQ_list_new)\n",
    "\n",
    "test_prevs_list = []\n",
    "test_next_list = []\n",
    "for timeseries in test_OQ_list_new:\n",
    "    prevs, nexts = decompose(timeseries)\n",
    "    for i in range(len(prevs)):\n",
    "        test_prevs_list.append(prevs[i])\n",
    "        test_next_list.append(nexts[i])\n",
    "true_vals = np.array(test_next_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define predictor classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalMeanGuesser():\n",
    "    def fit(self, train_OQ_list):\n",
    "        self.global_mean = np.mean(np.concatenate(train_OQ_list))\n",
    "    def predict(self, oq):\n",
    "        return self.global_mean\n",
    "    def predict_full_data(self, data):\n",
    "        return np.full(len(data), self.global_mean)\n",
    "    \n",
    "class PersonalMeanGuesser():\n",
    "    def predict(self, oq):\n",
    "        return np.mean(oq)\n",
    "\n",
    "class FirstScoreGuesser():\n",
    "    def predict(self, oq):\n",
    "        return oq[0]\n",
    "\n",
    "class LastScoreGuesser():\n",
    "    def predict(self, oq):\n",
    "        return oq[-1]\n",
    "\n",
    "class DumbLineGuesser(): #Guess that they'll follow the average slope of the series; not line of best fit, just last-first\n",
    "    def predict(self, oq):\n",
    "        if len(oq) == 1:\n",
    "            return oq[0]\n",
    "        else:\n",
    "            return oq[-1]+(oq[-1]-oq[0])/(len(oq)-1)\n",
    "    \n",
    "class SmartLineGuesser(): #Get a line of best fit\n",
    "    def predict(self, oq):\n",
    "        linreg = LinearRegression()\n",
    "        linreg.fit(np.expand_dims(np.arange(len(oq)), 0).reshape(-1,1), oq)\n",
    "        return linreg.predict(np.expand_dims(np.array([len(oq)]),0))[0]\n",
    "\n",
    "class GlobalMedianGuesser():\n",
    "    def fit(self, train_OQ_list):\n",
    "        self.global_median = np.median(np.concatenate(train_OQ_list))\n",
    "    def predict(self, oq):\n",
    "        return self.global_median\n",
    "    def predict_full_data(self, data):\n",
    "        return np.full(len(data), self.global_median)\n",
    "\n",
    "class PersonalMedianGuesser():\n",
    "    def predict(self, oq):\n",
    "        return np.median(oq)\n",
    "\n",
    "class LastMeanMidpointGuesser():\n",
    "    def predict(self,oq):\n",
    "        return np.mean([np.mean(oq), oq[-1]])\n",
    "    \n",
    "class LastMedianMidpointGuesser():\n",
    "    def predict(self,oq):\n",
    "        return np.mean([np.median(oq), oq[-1]])\n",
    "\n",
    "class LastDumblineMidpointGuesser():\n",
    "    def predict(self, oq):\n",
    "        if len(oq) == 1:\n",
    "            return oq[0]\n",
    "        else:\n",
    "            return np.mean([oq[-1]+(oq[-1]-oq[0])/(len(oq)-1), oq[-1]])\n",
    "\n",
    "class LastSmartlineMidpointGuesser():\n",
    "    def predict(self, oq):\n",
    "        linreg = LinearRegression()\n",
    "        linreg.fit(np.expand_dims(np.arange(len(oq)), 0).reshape(-1,1), oq)\n",
    "        return np.mean([linreg.predict(np.expand_dims(np.array([len(oq)]),0))[0], oq[-1]])\n",
    "\n",
    "class LastSmartlineMeanFusionGuesser():\n",
    "    def predict(self,oq):\n",
    "        linreg = LinearRegression()\n",
    "        linreg.fit(np.expand_dims(np.arange(len(oq)), 0).reshape(-1,1), oq)\n",
    "        return np.mean([linreg.predict(np.expand_dims(np.array([len(oq)]),0))[0], oq[-1], np.mean(oq)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_error_dict = {} # To match a description of each baseline with its list of absolute errors\n",
    "\n",
    "global_mean_guesser = GlobalMeanGuesser()\n",
    "global_mean_guesser.fit(train_OQ_list_new)\n",
    "global_mean_abs_errors = np.abs(np.array([global_mean_guesser.predict(test_data) for test_data in test_prevs_list])-true_vals)\n",
    "name_error_dict['Global mean'] = global_mean_abs_errors\n",
    "\n",
    "personal_mean_guesser = PersonalMeanGuesser()\n",
    "personal_mean_abs_errors = np.abs(np.array([personal_mean_guesser.predict(test_data) for test_data in test_prevs_list])-true_vals)\n",
    "name_error_dict['Personal mean'] = personal_mean_abs_errors\n",
    "\n",
    "first_score_guesser = FirstScoreGuesser()\n",
    "first_score_abs_errors = np.abs(np.array([first_score_guesser.predict(test_data) for test_data in test_prevs_list])-true_vals)\n",
    "name_error_dict['First score'] = first_score_abs_errors\n",
    "\n",
    "last_score_guesser = LastScoreGuesser()\n",
    "last_score_abs_errors = np.abs(np.array([last_score_guesser.predict(test_data) for test_data in test_prevs_list])-true_vals)\n",
    "name_error_dict['Last score'] = last_score_abs_errors\n",
    "\n",
    "dumb_line_guesser = DumbLineGuesser()\n",
    "dumb_line_abs_errors = np.abs(np.array([dumb_line_guesser.predict(test_data) for test_data in test_prevs_list])-true_vals)\n",
    "name_error_dict['Dumb line'] = dumb_line_abs_errors\n",
    "\n",
    "smart_line_guesser = SmartLineGuesser()\n",
    "smart_line_abs_errors = np.abs(np.array([smart_line_guesser.predict(test_data) for test_data in test_prevs_list])-true_vals)\n",
    "name_error_dict['Smart line'] = smart_line_abs_errors\n",
    "\n",
    "global_median_guesser = GlobalMedianGuesser()\n",
    "global_median_abs_errors = np.abs(np.array([global_median_guesser.predict(test_data) for test_data in test_prevs_list])-true_vals)\n",
    "name_error_dict['Global median'] = global_median_abs_errors\n",
    "\n",
    "personal_median_guesser = PersonalMedianGuesser()\n",
    "personal_median_abs_errors = np.abs(np.array([personal_median_guesser.predict(test_data) for test_data in test_prevs_list])-true_vals)\n",
    "name_error_dict['Personal median'] = personal_median_abs_errors\n",
    "\n",
    "last_mean_midpoint_guesser = LastMeanMidpointGuesser()\n",
    "last_mean_midpoint_abs_errors = np.abs(np.array([last_mean_midpoint_guesser.predict(test_data) for test_data in test_prevs_list])-true_vals)\n",
    "name_error_dict['Last-mean midpoint'] = last_mean_midpoint_abs_errors\n",
    "\n",
    "last_median_midpoint_guesser = LastMedianMidpointGuesser()\n",
    "last_median_midpoint_abs_errors = np.abs(np.array([last_median_midpoint_guesser.predict(test_data) for test_data in test_prevs_list])-true_vals)\n",
    "name_error_dict['Last-median midpoint'] = last_median_midpoint_abs_errors\n",
    "\n",
    "last_dumbline_midpoint_guesser = LastDumblineMidpointGuesser()\n",
    "last_dumbline_midpoint_abs_errors = np.abs(np.array([last_dumbline_midpoint_guesser.predict(test_data) for test_data in test_prevs_list])-true_vals)\n",
    "name_error_dict['Last-dumbline midpoint'] = last_dumbline_midpoint_abs_errors\n",
    "\n",
    "last_smartline_midpoint_guesser = LastSmartlineMidpointGuesser()\n",
    "last_smartline_midpoint_abs_errors = np.abs(np.array([last_smartline_midpoint_guesser.predict(test_data) for test_data in test_prevs_list])-true_vals)\n",
    "name_error_dict['Last-smartline midpoint'] = last_smartline_midpoint_abs_errors\n",
    "\n",
    "last_smartline_mean_fusion_guesser = LastSmartlineMeanFusionGuesser()\n",
    "last_smartline_mean_fusion_abs_errors = np.abs(np.array([last_smartline_mean_fusion_guesser.predict(test_data) for test_data in test_prevs_list])-true_vals)\n",
    "name_error_dict['Last-smartline-mean fusion'] = last_smartline_mean_fusion_abs_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in name_error_dict.keys():\n",
    "    print(f\"{key}: MSE = {np.mean(name_error_dict[key]**2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error with credible intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = {}\n",
    "for key in name_error_dict.keys():\n",
    "    abs_errors = name_error_dict[key]\n",
    "    mae_estimate = np.mean(abs_errors)\n",
    "    nonzero_errors = abs_errors.copy()\n",
    "    nonzero_errors[nonzero_errors==0]=REPLACE_VAL\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        #Put priors on the mean and variance, then derive the corresponding gamma distribution and do inference\n",
    "        mean = pm.Normal('mean', means_mean, sigma=np.sqrt(means_var))\n",
    "        var = pm.Gamma('var', alpha=vars_a, beta=vars_b)\n",
    "        y = pm.Gamma('absolute error', alpha=mean**2/var, beta=mean/var, observed=nonzero_errors)\n",
    "        trace=pm.sample(25000)\n",
    "    \n",
    "    all_mean_draws = np.concatenate(np.array(trace['posterior']['mean']))\n",
    "    cutoff_idx = int(.025*len(all_mean_draws)) #Find where to pull for the 2.5th percentile\n",
    "    lower_bound = np.sort(all_mean_draws)[cutoff_idx]\n",
    "    upper_bound = np.sort(all_mean_draws)[-cutoff_idx-1]\n",
    "    output_dict[key] = f\"{key}: MAE = {mae_estimate} ({lower_bound}-{upper_bound})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in output_dict.keys():\n",
    "    print(output_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_mean_OQ_train = np.mean(np.concatenate(train_OQ_list_new))\n",
    "overall_stdev_OQ_train = np.std(np.concatenate(train_OQ_list_new))\n",
    "#IMPORTANT! These have specific names because WidthRidge (below) relies on locals with those names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A wrapper that allows cross-validation grid search of a Ridge model with dataset width as a parameter\n",
    "class WidthRidge(Ridge):\n",
    "\n",
    "    def __init__(self, df_width=1, impute_val=None, use_intake=False, restrict_to_intake=False, exclude_cols = ['Timeseries', 'PatientID', 'SessionID', 'StartDate', 'EndDate', 'NumOfAttended', 'EndDate_intake', 'LastAppShowed', 'AttendRate', 'notedate', 'DateDifference', 'TherapistID', 'NursingOrLaw', 'ReligiousMinority', 'Crisis'], alpha=1.0, fit_intercept=True, copy_X=True, max_iter=None, tol=0.0001, solver='auto', positive=False, random_state=None):\n",
    "\n",
    "        super().__init__(alpha=alpha, fit_intercept=fit_intercept, copy_X=copy_X, max_iter=max_iter, tol=tol, solver=solver, positive=positive, random_state=random_state)\n",
    "        self.df_width = df_width\n",
    "        self.impute_val = impute_val\n",
    "        self.use_intake = use_intake #Actually train on intake info\n",
    "        self.restrict_to_intake = restrict_to_intake or self.use_intake #Only use rows that had intake data\n",
    "        self.exclude_cols = exclude_cols\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None): #y is a necessary dummy\n",
    "        #Assume that X is actually a set of variable-length time series, which we turn into data and labels\n",
    "        if self.restrict_to_intake:\n",
    "            known_X = X[[col for col in X.columns if col not in self.exclude_cols]]\n",
    "            self.train_feature_means = np.array(np.mean(known_X, axis=0))\n",
    "            self.train_feature_stdevs = np.array(np.std(known_X, axis=0))\n",
    "            timeseries_list_train = [timeseries for timeseries in X['Timeseries'] if len(timeseries) > 1]\n",
    "            num_rows_per_series_train = [len(timeseries)-1 for timeseries in timeseries_list_train]\n",
    "            index_list_train = []\n",
    "            for i, count in enumerate(num_rows_per_series_train):\n",
    "                index_list_train = index_list_train+[i]*count\n",
    "            mean = np.mean(np.concatenate(timeseries_list_train))\n",
    "            stdev = np.mean(np.concatenate(timeseries_list_train))\n",
    "        else:\n",
    "            mean = np.mean(np.concatenate(X))\n",
    "\n",
    "        if self.impute_val is None:\n",
    "            self.impute_val = mean\n",
    "        \n",
    "        if self.restrict_to_intake:\n",
    "            #normalize\n",
    "            data_train, labels_train = make_data_rectangular(timeseries_list_train, df_width=self.df_width, impute_val=self.impute_val)\n",
    "            data_train = (data_train - mean)/stdev\n",
    "            assert len(data_train) == len(index_list_train)\n",
    "            if self.use_intake:\n",
    "                intake_array_train = np.array(known_X)[index_list_train,:]\n",
    "                intake_array_train = (intake_array_train - self.train_feature_means)/ self.train_feature_stdevs\n",
    "                assert len(intake_array_train) == len(data_train)\n",
    "                full_array_train = np.hstack([intake_array_train, data_train])\n",
    "                super().fit(full_array_train, labels_train)\n",
    "            else:\n",
    "                super().fit(data_train, labels_train)\n",
    "        else:\n",
    "            train_data, train_labels = make_data_rectangular(X, df_width=self.df_width, impute_val=self.impute_val)\n",
    "            super().fit(train_data, train_labels, sample_weight=sample_weight)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        #Note: If things aren't all already df_width in width,\n",
    "        #   this will produce a different number of outputs than rows in X!!\n",
    "        \n",
    "        if self.use_intake: #If this is true, restrict_to_intake must be too\n",
    "            known_X = X[[col for col in X.columns if col not in self.exclude_cols]]\n",
    "            timeseries_list_val = [timeseries for timeseries in X['Timeseries'] if len(timeseries) > 1]\n",
    "            num_rows_per_series_val = [len(timeseries)-1 for timeseries in timeseries_list_val]\n",
    "            index_list_val = []\n",
    "            for i, count in enumerate(num_rows_per_series_val):\n",
    "                index_list_val = index_list_val+[i]*count\n",
    "\n",
    "            data_val, labels_val = make_data_rectangular(timeseries_list_val, self.df_width)\n",
    "            data_val = (data_val - overall_mean_OQ_train)/overall_stdev_OQ_train\n",
    "            assert len(data_val) == len(index_list_val)\n",
    "            intake_array_val = np.array(known_X)[index_list_val,:]\n",
    "            intake_array_val = (intake_array_val - self.train_feature_means)/self.train_feature_stdevs\n",
    "            assert len(intake_array_val) == len(data_val)\n",
    "            full_array_val = np.hstack([intake_array_val, data_val])\n",
    "            return super().predict(full_array_val)\n",
    "\n",
    "        else:\n",
    "            val_data, val_labels = make_data_rectangular(X, df_width=self.df_width, impute_val=self.impute_val)\n",
    "            return super().predict(val_data)\n",
    "        \n",
    "    def score(self, X, y, sample_weight = None):\n",
    "        #Overriding to use MSE (or rather, negative MSE)\n",
    "        if self.use_intake: #If this is true, restrict_to_intake must be too\n",
    "            known_X = X[[col for col in X.columns if col not in self.exclude_cols]]\n",
    "            timeseries_list_val = [timeseries for timeseries in X['Timeseries'] if len(timeseries) > 1]\n",
    "            num_rows_per_series_val = [len(timeseries)-1 for timeseries in timeseries_list_val]\n",
    "            index_list_val = []\n",
    "            for i, count in enumerate(num_rows_per_series_val):\n",
    "                index_list_val = index_list_val+[i]*count\n",
    "\n",
    "            data_val, val_labels = make_data_rectangular(timeseries_list_val, self.df_width)\n",
    "            data_val = (data_val - overall_mean_OQ_train)/overall_stdev_OQ_train\n",
    "            assert len(data_val) == len(index_list_val)\n",
    "            intake_array_val = np.array(known_X)[index_list_val,:]\n",
    "            intake_array_val = (intake_array_val - self.train_feature_means)/self.train_feature_stdevs\n",
    "            assert len(intake_array_val) == len(data_val)\n",
    "            full_array_val = np.hstack([intake_array_val, data_val])\n",
    "            predictions = super().predict(full_array_val)\n",
    "\n",
    "        else:\n",
    "            val_data, val_labels = make_data_rectangular(X, df_width=self.df_width, impute_val=self.impute_val)\n",
    "            predictions = super().predict(val_data)\n",
    "        return -1*mean_squared_error(predictions, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = WidthRidge()\n",
    "\n",
    "param_grid = {'alpha':[0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'df_width':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20],\n",
    "              'tol':[0.00001, 0.0001, 0.001],\n",
    "              'solver':['auto','svd','cholesky','lsqr','saga'],\n",
    "              'random_state':[64]}\n",
    "\n",
    "grid_searcher = GridSearchCV(ridge_model, param_grid, cv=3, verbose=2)\n",
    "\n",
    "grid_searcher.fit(train_OQ_list_new, np.zeros(len(train_OQ_list_new)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_searcher.best_params_)\n",
    "params_dict = {key:grid_searcher.best_params_[key] for key in grid_searcher.best_params_.keys() if key != 'df_width'}\n",
    "best_width = grid_searcher.best_params_['df_width']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors, MSE, MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = Ridge(**params_dict)\n",
    "\n",
    "train_data, train_labels = make_data_rectangular(train_OQ_list_new, df_width=best_width, impute_val=overall_mean_OQ_train)\n",
    "test_data, test_labels = make_data_rectangular(test_OQ_list_new, df_width=best_width, impute_val=overall_mean_OQ_train)\n",
    "\n",
    "\n",
    "ridge_model.fit(train_data, train_labels)\n",
    "predictions = ridge_model.predict(test_data)\n",
    "abs_errors = np.abs(predictions-test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ridge_model.coef_)\n",
    "print(ridge_model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE: {np.mean(abs_errors**2)}\")\n",
    "print(f\"MAE: {np.mean(abs_errors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credible Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_errors = abs_errors.copy()\n",
    "nonzero_errors[nonzero_errors==0]=REPLACE_VAL\n",
    "\n",
    "with pm.Model() as model:\n",
    "    mean = pm.Normal('mean', means_mean, sigma=np.sqrt(means_var))\n",
    "    var = pm.Gamma('var', alpha=vars_a, beta=vars_b)\n",
    "    y = pm.Gamma('absolute error', alpha=mean**2/var, beta=mean/var, observed=nonzero_errors)\n",
    "    trace=pm.sample(25000)\n",
    "\n",
    "all_mean_draws = np.concatenate(np.array(trace['posterior']['mean']))\n",
    "cutoff_idx = int(.025*len(all_mean_draws))\n",
    "lower_bound = np.sort(all_mean_draws)[cutoff_idx]\n",
    "upper_bound = np.sort(all_mean_draws)[-cutoff_idx-1]\n",
    "print(f\"{lower_bound}-{upper_bound}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WidthRF(RandomForestRegressor):\n",
    "    def __init__(self, df_width=1, n_estimators=100, criterion='squared_error', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=1.0, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None):\n",
    "\n",
    "        super().__init__(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, min_weight_fraction_leaf=min_weight_fraction_leaf, max_features=max_features, max_leaf_nodes=max_leaf_nodes, min_impurity_decrease=min_impurity_decrease, bootstrap=bootstrap, oob_score=oob_score, n_jobs=n_jobs, random_state=random_state, verbose=verbose, warm_start=warm_start, ccp_alpha=ccp_alpha, max_samples=max_samples)\n",
    "        self.df_width = df_width\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None): #y is a necessary dummy\n",
    "        #Assume that X is actually a set of variable-length time series, which we turn into data and labels\n",
    "        mean = np.mean(np.concatenate(X))\n",
    "        self.mean_val = mean\n",
    "        train_data, train_labels = make_data_rectangular(X, df_width=self.df_width, impute_val=mean)\n",
    "        super().fit(train_data, train_labels, sample_weight=sample_weight)\n",
    "\n",
    "    def predict(self, X):\n",
    "        #Note: If things aren't all already df_width in width,\n",
    "        #   this will produce a different number of outputs than rows in X!!\n",
    "        val_data, val_labels = make_data_rectangular(X, df_width=self.df_width, impute_val=self.mean_val)\n",
    "        return super().predict(val_data)\n",
    "    \n",
    "    def score(self, X, y, sample_weight = None):\n",
    "        #Overriding to use MSE (or negative MSE)\n",
    "        val_data, val_labels = make_data_rectangular(X, df_width=self.df_width, impute_val=self.mean_val)\n",
    "        predictions = super().predict(val_data)\n",
    "        return -1*mean_squared_error(predictions, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_full_data = WidthRF()\n",
    "\n",
    "param_grid = {'n_estimators':[75,100,125],\n",
    "                    'max_depth':[None, 5,10,20],\n",
    "                    'min_samples_leaf':[1,2,4],\n",
    "                    'max_features':['sqrt',None,0.5],\n",
    "                    'df_width':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20],\n",
    "                    'random_state':[64]}\n",
    "\n",
    "grid_searcher = GridSearchCV(forest_full_data, param_grid, cv=3, verbose=2)\n",
    "\n",
    "grid_searcher.fit(train_OQ_list_new, np.zeros(len(train_OQ_list_new)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_searcher.best_params_)\n",
    "params_dict = {key:grid_searcher.best_params_[key] for key in grid_searcher.best_params_.keys() if key != 'df_width'}\n",
    "best_width = grid_searcher.best_params_['df_width']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error, MSE, MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "rf_model = RandomForestRegressor(**params_dict)\n",
    "\n",
    "train_data, train_labels = make_data_rectangular(train_OQ_list_new, df_width=best_width, impute_val=overall_mean_OQ_train)\n",
    "rf_model.fit(train_data, train_labels)\n",
    "\n",
    "val_data, val_labels = make_data_rectangular(val_OQ_list_new, df_width=best_width, impute_val=overall_mean_OQ_train)\n",
    "predictions = rf_model.predict(val_data)\n",
    "\n",
    "abs_errors = np.abs(predictions-test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE: {np.mean(abs_errors**2)}\")\n",
    "print(f\"MAE: {np.mean(abs_errors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credible intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_errors = abs_errors.copy()\n",
    "nonzero_errors[nonzero_errors==0]=REPLACE_VAL\n",
    "\n",
    "with pm.Model() as model:\n",
    "    mean = pm.Normal('mean', means_mean, sigma=np.sqrt(means_var))\n",
    "    var = pm.Gamma('var', alpha=vars_a, beta=vars_b)\n",
    "    y = pm.Gamma('absolute error', alpha=mean**2/var, beta=mean/var, observed=nonzero_errors)\n",
    "    trace=pm.sample(25000)\n",
    "    \n",
    "all_mean_draws = np.concatenate(np.array(trace['posterior']['mean']))\n",
    "cutoff_idx = int(.025*len(all_mean_draws))\n",
    "lower_bound = np.sort(all_mean_draws)[cutoff_idx]\n",
    "upper_bound = np.sort(all_mean_draws)[-cutoff_idx-1]\n",
    "print(f\"{lower_bound}-{upper_bound}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Therapist predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample test data for therapists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_data_new.pkl', 'rb') as file:\n",
    "    test_data_df = pickle.Unpickler(file=file).load()\n",
    "\n",
    "master_df_2_test = pd.read_csv('master_df_2_cu003_thesis_hiddenClients.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#120 for each three therapists (one unused)\n",
    "np.random.seed(499)\n",
    "observation_indices = np.random.choice(len(test_data_df), size=360, replace=False)\n",
    "sub_df = test_data_df.iloc[observation_indices].reset_index()[['Session','Previous', 'Next']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Record which sessions, and where, are being given to therapists so we can link them to the true values later\n",
    "rows_list = []\n",
    "num_timeseries_per_therapist = 120\n",
    "for therapist_num in range(3):\n",
    "    for row_idx in range(120):\n",
    "        row = sub_df.iloc[therapist_num*num_timeseries_per_therapist + row_idx]\n",
    "        rows_list.append({'Study Therapist Index': therapist_num, 'Observation Index': row_idx, 'Session ID': row['Session'], '# of Previous OQs': len(row['Previous'])})\n",
    "\n",
    "therapist_match_df = pd.DataFrame(rows_list)\n",
    "therapist_match_df.to_csv('data_linking_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These won't be reported directly, either for anonymity (not reported at all) or because their information is captured elsewhere\n",
    "exclude_cols = ['PatientID', 'TherapistID', 'StartDate', 'EndDate', 'SessionID', 'NumOfAttended', 'Crisis', 'notedate', 'DateDifference', 'Date of Birth', 'Freshman / First-year', 'Sophomore', 'Junior', 'Senior', 'Graduate / professional degree student', 'Military Stress']\n",
    "\n",
    "def detransform_features(features_series):\n",
    "    #Takes in a pandas series of features from master_frame_2 and turns the numbers back into verbal responses\n",
    "    #Well, in particular, it returns a long string with printed feature: answer pairs\n",
    "    #More or less undoes what the data cleaning does to parse the patient info file\n",
    "\n",
    "    def isnull(val):\n",
    "        if val is None:\n",
    "            return True\n",
    "        if type(val) == float or isinstance(val, np.floating):\n",
    "            return math.isnan(val)\n",
    "        return False\n",
    "    \n",
    "    #Define functions to parse the most common answer types\n",
    "\n",
    "    def get_bool_result(col_name):\n",
    "        input = features_series[col_name]\n",
    "        return \"No response\" if isnull(input) else (\"Yes\" if input else \"No\")\n",
    "    \n",
    "    def get_stress_result(col_name):\n",
    "        input = features_series[col_name]\n",
    "        if isnull(input):\n",
    "            return \"No response\"\n",
    "        try:\n",
    "            assert type(input) == int\n",
    "        except:\n",
    "            input=int(input)\n",
    "        assert input < 5 and input >= 0\n",
    "        if not input:\n",
    "            amount_str = \"Never\"\n",
    "        elif input==1:\n",
    "            amount_str = \"Rarely\"\n",
    "        elif input==2:\n",
    "            amount_str = \"Sometimes\"\n",
    "        elif input==3:\n",
    "            amount_str = \"Often\"\n",
    "        else:\n",
    "            amount_str = \"Always\"\n",
    "        return amount_str + \" stressful\"\n",
    "    \n",
    "    def get_howmany_result(col_name):\n",
    "        input = features_series[col_name]\n",
    "        if isnull(input):\n",
    "            return \"No response\"\n",
    "        try:\n",
    "            assert type(input) == int\n",
    "        except:\n",
    "            input=int(input)\n",
    "        assert input < 5 and input >= 0\n",
    "        if not input:\n",
    "            ans_str = \"Never\"\n",
    "        elif input==1:\n",
    "            ans_str = \"1 time\"\n",
    "        elif input==2:\n",
    "            ans_str = \"2-3 times\"\n",
    "        elif input==3:\n",
    "            ans_str = \"4-5 times\"\n",
    "        else:\n",
    "            ans_str = \"More than 5 times\"\n",
    "        return ans_str\n",
    "    \n",
    "    def get_sleep_result(col_name):\n",
    "        input = features_series[col_name]\n",
    "        if isnull(input):\n",
    "            return \"No response\"\n",
    "        try:\n",
    "            assert type(input) == int\n",
    "        except:\n",
    "            input=int(input)\n",
    "        assert input < 3 and input >= 0\n",
    "        if not input:\n",
    "            ans_str = \"Rarely (0-1 nights)\"\n",
    "        elif input==1:\n",
    "            ans_str = \"Sometimes (2-3 nights)\"\n",
    "        else:\n",
    "            ans_str = \"Often (4+ nights)\"\n",
    "        return ans_str\n",
    "    \n",
    "    def get_support_result(col_name):\n",
    "        input = features_series[col_name]\n",
    "        if isnull(input):\n",
    "            return \"No response\"\n",
    "        try:\n",
    "            assert type(input) == int\n",
    "        except:\n",
    "            input=int(input)\n",
    "        assert input < 3 and input >= -2\n",
    "        if not input:\n",
    "            return \"Neutral\"\n",
    "        if input==-2:\n",
    "            pre_str = \"Strongly dis\"\n",
    "        elif input==-1:\n",
    "            pre_str = \"Somewhat dis\"\n",
    "        elif input==1:\n",
    "            pre_str = \"Somewhat \"\n",
    "        else:\n",
    "            pre_str = \"Strongly \"\n",
    "        return pre_str + \"agree\"\n",
    "    \n",
    "    def get_religion_result(col_name):\n",
    "        input = features_series[col_name]\n",
    "        if isnull(input):\n",
    "            return \"No response\"\n",
    "        try:\n",
    "            assert type(input) == int\n",
    "        except:\n",
    "            input=int(input)\n",
    "        assert input < 3 and input >= -2\n",
    "        if not input:\n",
    "            return \"Neutral\"\n",
    "        if input == 1:\n",
    "            return \"Important\"\n",
    "        if input==-2:\n",
    "            pre_str = \"Very un\"\n",
    "        elif input==-1:\n",
    "            pre_str = \"Un\"\n",
    "        else:\n",
    "            pre_str = \"Very \"\n",
    "        return pre_str + \"important\"\n",
    "    \n",
    "    def get_int_result(col_name):\n",
    "        input = features_series[col_name]\n",
    "        if isnull(input):\n",
    "            return \"No response\"\n",
    "        return int(input)\n",
    "    \n",
    "    def get_social_media_result(col_name):\n",
    "        input = features_series[col_name]\n",
    "        if isnull(input):\n",
    "            return \"No response\"\n",
    "        try:\n",
    "            assert type(input) == int\n",
    "        except:\n",
    "            input=int(input)\n",
    "        assert input < 6 and input >= 1\n",
    "        if input == 1:\n",
    "            return \"Mostly negative\"\n",
    "        if input==2:\n",
    "            return \"Somewhat negative\"\n",
    "        if input==3:\n",
    "            return \"Somewhat positive\"\n",
    "        if input == 4:\n",
    "            return \"Mostly positive\"\n",
    "        return \"I do not use social media\"\n",
    "    \n",
    "    def get_sex_result(col_name):\n",
    "        input = features_series[col_name]\n",
    "        if isnull(input):\n",
    "            return \"No response\"\n",
    "        return (\"Female\" if input else \"Male\")\n",
    "    \n",
    "    # Abbreviate or line-break long questions\n",
    "\n",
    "    disability_q = \"Are you registered, with the office for disability services on this campus, as having a documented and diagnosed disability?\"\n",
    "    formatted_disability_q = \"Are you registered, with the office for disability services on this campus,\\n\\tas having a documented and diagnosed disability?\"\n",
    "\n",
    "    disability_codes = {\n",
    "        'If you selected, \"Yes\" for the previous question, please indicate which category of disability you are registered for (check all that apply) ANSWER: Difficulty hearing': 'Difficulty hearing',\n",
    "        'If you selected, \"Yes\" for the previous question, please indicate which category of disability you are registered for (check all that apply) ANSWER: Difficulty seeing': 'Difficulty seeing',\n",
    "        'If you selected, \"Yes\" for the previous question, please indicate which category of disability you are registered for (check all that apply) ANSWER: Difficulty speaking or language impairment': 'Difficulty speaking or language impairment',\n",
    "        'If you selected, \"Yes\" for the previous question, please indicate which category of disability you are registered for (check all that apply) ANSWER: Mobility limitation/ orthopedic impairment': 'Mobility limitation/ orthopedic impairment',\n",
    "        'If you selected, \"Yes\" for the previous question, please indicate which category of disability you are registered for (check all that apply) ANSWER: Traumatic brain injury': 'Traumatic brain injury',\n",
    "        'If you selected, \"Yes\" for the previous question, please indicate which category of disability you are registered for (check all that apply) ANSWER: Specific learning disabilities': 'Specific learning disabilities',\n",
    "        'If you selected, \"Yes\" for the previous question, please indicate which category of disability you are registered for (check all that apply) ANSWER: ADD or ADHD': 'ADD or ADHD',\n",
    "        'If you selected, \"Yes\" for the previous question, please indicate which category of disability you are registered for (check all that apply) ANSWER: Autism spectrum disorders': 'Autism spectrum disorder',\n",
    "        'If you selected, \"Yes\" for the previous question, please indicate which category of disability you are registered for (check all that apply) ANSWER: Cognitive difficulties or intellectual disability': 'Cognitive difficulties or intellectual disability',\n",
    "        'If you selected, \"Yes\" for the previous question, please indicate which category of disability you are registered for (check all that apply) ANSWER: Health impairment/ condition, including chronic conditions': 'Health impairment/ condition, including chronic conditions',\n",
    "        'If you selected, \"Yes\" for the previous question, please indicate which category of disability you are registered for (check all that apply) ANSWER: Psychological or psychiatric condition': 'Psychological or psychiatric condition',\n",
    "        'If you selected, \"Yes\" for the previous question, please indicate which category of disability you are registered for (check all that apply) ANSWER: Other': 'Other'\n",
    "    }\n",
    "\n",
    "    trauma_codes = {\n",
    "        'Please select the traumatic event(s) you have experienced ANSWER: Childhood physical abuse': 'Childhood physical abuse',\n",
    "        'Please select the traumatic event(s) you have experienced ANSWER: Childhood sexual abuse': 'Childhood sexual abuse',\n",
    "        'Please select the traumatic event(s) you have experienced ANSWER: Childhood emotional abuse': 'Childhood emotional abuse',\n",
    "        'Please select the traumatic event(s) you have experienced ANSWER: Physical attack (e.g., mugged, beaten up, shot, stabbed, threatened with weapon)': 'Physical attack',\n",
    "        'Please select the traumatic event(s) you have experienced ANSWER: Sexual violence (rape or attempted rape, sexually assaulted, stalked, abused by intimate partner, etc.)': 'Sexual violence',\n",
    "        'Please select the traumatic event(s) you have experienced ANSWER: Military combat or war zone experiences': 'Military combat or war zone experiences',\n",
    "        'Please select the traumatic event(s) you have experienced ANSWER: Kidnapped or taken hostage': 'Kidnapped or taken hostage',\n",
    "        'Please select the traumatic event(s) you have experienced ANSWER: Serious accident, fire, or explosion (e.g., an industrial, farm, car, plane, or boating accident)': 'Serious accident, fire, or explosion',\n",
    "        'Please select the traumatic event(s) you have experienced ANSWER: Terrorist attack': 'Terrorist attack',\n",
    "        'Please select the traumatic event(s) you have experienced ANSWER: Near drowning': 'Near drowning',\n",
    "        'Please select the traumatic event(s) you have experienced ANSWER: Diagnosed with life threatening illness': 'Diagnosed with life-threatening illness',\n",
    "        'Please select the traumatic event(s) you have experienced ANSWER: Natural disaster (e.g., flood, quake, hurricane, etc.)': 'Natural disaster',\n",
    "        'Please select the traumatic event(s) you have experienced ANSWER: Imprisonment or Torture': 'Imprisonment or torture',\n",
    "        'Please select the traumatic event(s) you have experienced ANSWER: Animal attack': 'Animal attack',\n",
    "        'Please select the traumatic event(s) you have experienced ANSWER: Other (please specify)': 'Other'\n",
    "    }\n",
    "\n",
    "    autism_q = \"Have you been diagnosed with an autism-spectrum disorder or Asperger's Syndrome?\"\n",
    "    formatted_autism_q = \"Have you been diagnosed with an autism-spectrum disorder\\n\\tor Asperger's Syndrome?\"\n",
    "    sleep_q_1 = \"In the past week, about how many nights has it taken you more than half an hour to fall asleep?\"\n",
    "    formatted_sleep_q_1 = \"In the past week, about how many nights has it taken\\n\\tyou more than half an hour to fall asleep?\"\n",
    "    sleep_q_2 = \"In the past week, about how many nights have you woken during the night AND needed more than half an hour to fall back to sleep?\"\n",
    "    formatted_sleep_q_2 = \"In the past week, about how many nights have you woken during\\n\\tthe night AND needed more than half an hour\\n\\tto fall back to sleep?\"\n",
    "    sleep_q_3 = \"In the past two weeks, have you taken a substance to help with sleep? Please consider prescription medication, over the counter medication and supplements, and substances such as alcohol and marijuana.\"\n",
    "    formatted_sleep_q_3 = \"In the past two weeks, have you taken a substance to help\\n\\twith sleep? Please consider prescription medication, over the counter\\n\\tmedication and supplements, and substances such as\\n\\talcohol and marijuana.\"\n",
    "\n",
    "    #More functions, to handle lists of true-falses where only the \"true\" answers are relevant\n",
    "    def generate_disability_list():\n",
    "        disabilities_list = []\n",
    "        for col in disability_codes.keys():\n",
    "            if features_series[col]:\n",
    "                disabilities_list.append(disability_codes[col])\n",
    "        return disabilities_list\n",
    "    \n",
    "    def generate_trauma_list():\n",
    "        trauma_list = []\n",
    "        for col in trauma_codes.keys():\n",
    "            if features_series[col]:\n",
    "                trauma_list.append(trauma_codes[col])\n",
    "        return trauma_list\n",
    "    \n",
    "    def find_academic_year():\n",
    "        for key in ['Freshman / First-year', 'Sophomore', 'Junior', 'Senior', 'Graduate / professional degree student']:\n",
    "            if features_series[key]:\n",
    "                return key\n",
    "        return \"No response\"\n",
    "\n",
    "    #Now: Link intake questions to something human-readable, separated mostly by order presented to therapists\n",
    "\n",
    "    explanation_dict_part_1 = {\n",
    "        'Female': 'Sex assigned at birth',\n",
    "        'age': 'Age',\n",
    "        'RacialMinority': 'Racial Minority',\n",
    "        'International Student': 'International Student',\n",
    "        'SexOrientationMinority': \"Sexual Orientation Minority\",\n",
    "        'MarriedMale': 'Married Male',\n",
    "        'NursingOrLaw': 'Nursing or Law Student',\n",
    "        disability_q: formatted_disability_q\n",
    "    }\n",
    "\n",
    "    #Which disabilities here\n",
    "\n",
    "    explanation_dict_part_2 = {\n",
    "        autism_q: formatted_autism_q,\n",
    "        'Homeless': 'Homeless',\n",
    "        'ROTC': 'ROTC Member',\n",
    "        'Military Service': 'Client Military Service'\n",
    "    }\n",
    "\n",
    "    #Break here to include military stress if they said yes to military service\n",
    "\n",
    "    #All of the \"recent\" will be conditional on the preceding \"how many\"\n",
    "    explanation_dict_part_3 = {\n",
    "        'First Generation': 'First-Generation College Student',\n",
    "        'Financial Stress Now': '\\nCurrent level of financial stress',\n",
    "        'Financial Stress Past': 'Level of financial stress while growing up',\n",
    "        'AgnosticOrAtheist': 'Agnostic or Atheist',\n",
    "        'ReligiousMinority': 'Religious Minority',\n",
    "        'Religion Importance': 'Importance of religion to client',\n",
    "        'Prior Counseling': 'Has the client ever gone to mental health counseling before?',\n",
    "        'Prior Meds': 'Has the client ever taken medication for mental health reasons?',\n",
    "        'Prior Hospitalization (How many)': '\\nHow many times has the client been\\n\\thospitalized for mental health reasons?',\n",
    "        'Prior Hospitalization (Recent)': 'Did the client indicate they had been\\n\\thospitalized for mental health reasons during the past year?',\n",
    "        'Need to Reduce D&A (How many)': 'How many times has the client felt a\\n\\tneed to reduce drug and alcohol use?',\n",
    "        'Need to Reduce D&A (Recent)': 'Did the client indicate they had felt a\\n\\tneed to reduce drug and alcohol use during the past year?',\n",
    "        'Others Concern Alcohol (How many)': \"How many times have others expressed to the client\\n\\tconcern about the client's drug and alcohol use?\",\n",
    "        'Others Concern Alcohol (Recent)': \"Did the client indicate that others expressed concern\\n\\tabout their drug and alcohol use during the past year?\",\n",
    "        'Prior D&A Treatment (How many)': \"How many times has the client received treatment\\n\\tfor their drug and alcohol use?\",\n",
    "        'Prior D&A Treatment (Recent)': \"Did the client indicate that they received treatment\\n\\tfor their drug and alcohol use in the past year?\",\n",
    "        'Self-Injury (How many)': \"How many times has the client injured themselves\\n\\twithout the intent to cause death?\",\n",
    "        'Self-Injury (Recent)': \"Did the client indicate they had injured themselves\\n\\twithout the intent to cause death in the past year?\",\n",
    "        'Considered Suicide (How many)': \"How many times has the client considered suicide?\",\n",
    "        'Considered Suicide (Recent)': \"Did the client indicate they had considered suicide\\n\\tin the past year?\",\n",
    "        'Suicide Attempt (How many)': \"How many times has the client attempted suicide?\",\n",
    "        'Suicide Attempt (Recent)': \"Did the client indicate they had\\n\\tattempted suicide in the past year?\",\n",
    "        'Considered Harming (How many)': \"How many times has the client considered\\n\\tcausing serious physical harm to another person?\",\n",
    "        'Considered Harming (Recent)': \"Did the client indicate they had considered\\n\\tcausing serious physical harm to another person in the past year?\",\n",
    "        'Harmed Another (How many)': \"How many times has the client intentionally injured another?\",\n",
    "        'Harmed Another (Recent)': \"Did the client indicate they had intentionally\\n\\tinjured another in the past year?\",\n",
    "        'Unwanted Sexual Exp. (How many)': \"How many times has the client had an unwanted\\n\\tsexual experience? (E.g. they were passed out,\\n\\tdrugged, threatened, etc.)\",\n",
    "        'Unwanted Sexual Exp. (Recent)': \"Did the client indicate they had an unwanted\\n\\tsexual experience in the past year?\",\n",
    "        'Harassment/Abuse (How many)': \"How many times has the client experienced harassing,\\n\\tcontrolling, or abusive behavior from another?\",\n",
    "        'Harassment/Abuse (Recent)': \"Did the client indicate they had experienced harassing,\\n\\tcontrolling, or abusive behavior from another in the past year?\",\n",
    "        'PTSD Experience (How many)': \"How many times has the client experienced a traumatic\\n\\tevent that cause a feeling of fear, helplessness, or horror?\",\n",
    "        'PTSD Experience (Recent)': \"Did the client indicate they had experienced a traumatic\\n\\tevent causing fear, helplessness, or horror in the past year?\"\n",
    "    }\n",
    "\n",
    "    explanation_dict_part_4 = {\n",
    "        'Family Support': '\\nDoes the client agree that they experience family support?',\n",
    "        'Social Support': 'Does the client agree that they experience social support?',\n",
    "        sleep_q_1: formatted_sleep_q_1,\n",
    "        sleep_q_2: formatted_sleep_q_2,\n",
    "        sleep_q_3: formatted_sleep_q_3,\n",
    "        'Academics': 'What is the impact of social media on your academics?',\n",
    "        'Social life/relationships': 'What is the impact of social media on\\n\\tyour social life / relationship?',\n",
    "        'Emotional well-being': 'What is the impact of social media on your\\n\\temotional well-being?',\n",
    "        'Confusion about religious beliefs or values': '\\nConfusion about religious beliefs or values',\n",
    "        'Gender, ethnic, or racial discrimination': 'Gender, ethnic, or racial discrimination',\n",
    "        'Perfectionism': 'Perfectionism',\n",
    "        'Physical health problems (headaches, GI trouble)': 'Physical health problems (headaches, GI trouble)',\n",
    "        'Sexual concerns': 'Sexual concerns',\n",
    "        'Sexual orientation or identity': 'Sexual orientation or identity',\n",
    "        'Pornography': 'Pornography'\n",
    "    }\n",
    "\n",
    "\n",
    "    all_explained_keys = []\n",
    "    for key in explanation_dict_part_1.keys():\n",
    "        all_explained_keys.append(key)\n",
    "    for key in explanation_dict_part_2.keys():\n",
    "        all_explained_keys.append(key)\n",
    "    for key in explanation_dict_part_3.keys():\n",
    "        all_explained_keys.append(key)\n",
    "    for key in explanation_dict_part_4.keys():\n",
    "        all_explained_keys.append(key)\n",
    "    for key in disability_codes.keys():\n",
    "        all_explained_keys.append(key)\n",
    "    for key in trauma_codes.keys():\n",
    "        all_explained_keys.append(key)\n",
    "\n",
    "    explanation_dict_part_5 = {col:col for col in features_series.index if (col not in all_explained_keys and col not in exclude_cols)}\n",
    "\n",
    "    #List features by which function is used to parse them\n",
    "    int_parser_features = ['age']\n",
    "    sex_parser_features = ['Female']\n",
    "    bool_parser_features = ['RacialMinority', 'International Student', 'SexOrientationMinority', 'MarriedMale', 'NursingOrLaw', disability_q, autism_q, 'Homeless', 'ROTC', 'Military Service', 'Military Stress', 'First Generation', 'AgnosticOrAtheist', 'ReligiousMinority', 'Prior Counseling', 'Prior Meds', 'Prior Hospitalization (Recent)', 'Need to Reduce D&A (Recent)', 'Others Concern Alcohol (Recent)', 'Prior D&A Treatment (Recent)', 'Self-Injury (Recent)', 'Considered Suicide (Recent)', 'Suicide Attempt (Recent)', 'Considered Harming (Recent)', 'Harmed Another (Recent)', 'Unwanted Sexual Exp. (Recent)', 'Harassment/Abuse (Recent)', 'PTSD Experience (Recent)']\n",
    "    stress_parser_features = ['Financial Stress Now', 'Financial Stress Past', 'Confusion about religious beliefs or values', 'Gender, ethnic, or racial discrimination', 'Perfectionism', 'Physical health problems (headaches, GI trouble)', 'Sexual concerns', 'Sexual orientation or identity', 'Pornography']\n",
    "    religion_parser_features = ['Religion Importance']\n",
    "    howmany_parser_features = ['Prior Hospitalization (How many)', 'Need to Reduce D&A (How many)', 'Others Concern Alcohol (How many)', 'Prior D&A Treatment (How many)', 'Self-Injury (How many)', 'Considered Suicide (How many)', 'Suicide Attempt (How many)', 'Considered Harming (How many)', 'Harmed Another (How many)', 'Unwanted Sexual Exp. (How many)', 'Harassment/Abuse (How many)', 'PTSD Experience (How many)']\n",
    "    support_parser_features = ['Family Support', 'Social Support']\n",
    "    sleep_parser_features = [sleep_q_1, sleep_q_2, sleep_q_3]\n",
    "    social_media_parser_features = ['Academics', 'Social life/relationships', 'Emotional well-being']\n",
    "\n",
    "    all_parsed_features = int_parser_features + sex_parser_features + bool_parser_features + stress_parser_features + religion_parser_features + howmany_parser_features + support_parser_features + sleep_parser_features + social_media_parser_features\n",
    "    int_parser_features = [col for col in features_series.index if (col not in all_parsed_features and col not in exclude_cols)] + int_parser_features\n",
    "\n",
    "    parser_dict = {col: get_int_result for col in int_parser_features}\n",
    "\n",
    "    #Set up parsing functions as a dictionary for easier coding\n",
    "    for col in sex_parser_features:\n",
    "        parser_dict[col] = get_sex_result\n",
    "    for col in bool_parser_features:\n",
    "        parser_dict[col] = get_bool_result\n",
    "    for col in stress_parser_features:\n",
    "        parser_dict[col] = get_stress_result\n",
    "    for col in religion_parser_features:\n",
    "        parser_dict[col] = get_religion_result\n",
    "    for col in howmany_parser_features:\n",
    "        parser_dict[col] = get_howmany_result\n",
    "    for col in support_parser_features:\n",
    "        parser_dict[col] = get_support_result\n",
    "    for col in sleep_parser_features:\n",
    "        parser_dict[col] = get_sleep_result\n",
    "    for col in social_media_parser_features:\n",
    "        parser_dict[col] = get_social_media_result\n",
    "\n",
    "    result_string = \"Below is a list of question-answer pairs and other information about\\nthe client's concerns and demographics. The format of the information varies,\\nbut 'you', 'I', and 'the client' all refer to the client.\\n\\n\"\n",
    "\n",
    "    #Put all the answers together into one big string\n",
    "    #Academic status first\n",
    "    result_string += f\"Academic status: {find_academic_year()}\\n\"\n",
    "    for key in explanation_dict_part_1.keys():\n",
    "        result_string += f\"{explanation_dict_part_1[key]}: {parser_dict[key](key)}\\n\"\n",
    "    #Disabilities\n",
    "    if features_series[disability_q]:\n",
    "        result_string += \"Registered categories of disabilities: \"\n",
    "        for disability in generate_disability_list():\n",
    "            result_string += disability+\", \"\n",
    "        result_string = result_string[:-2] + \"\\n\"\n",
    "    \n",
    "    for key in explanation_dict_part_2.keys():\n",
    "        result_string += f\"{explanation_dict_part_2[key]}: {parser_dict[key](key)}\\n\"\n",
    "    if features_series['Military Service']:\n",
    "        result_string += f\"Military service included stressful or traumatic experience that continues to bother the client: {get_bool_result('Military Stress')}\\n\"\n",
    "\n",
    "    for key in explanation_dict_part_3.keys():\n",
    "        if '(Recent)' not in key:\n",
    "            result_string += f\"{explanation_dict_part_3[key]}: {parser_dict[key](key)}\\n\"\n",
    "        else:\n",
    "            root_question = key[:-7]+'How many)'\n",
    "            if features_series[root_question]:\n",
    "                result_string += f\"{explanation_dict_part_3[key]}: {parser_dict[key](key)}\\n\"\n",
    "    \n",
    "    if features_series['PTSD Experience (How many)']:\n",
    "        result_string += \"Types of past traumatic events:\\n\\t\"\n",
    "        for trauma in generate_trauma_list():\n",
    "            result_string += trauma+\", \"\n",
    "        result_string = result_string[:-2] + \"\\n\"\n",
    "\n",
    "    for key in explanation_dict_part_4.keys():\n",
    "        result_string += f\"{explanation_dict_part_4[key]}: {parser_dict[key](key)}\\n\"\n",
    "\n",
    "    result_string+=\"\\n--Note: The remaining questions come from the CCAPS,\\n\\twhich ranks answers on a 5-point scale from\\n\\t0 (not at all like me) and 4 (extremely like me).--\\n\\n\"\n",
    "    for key in explanation_dict_part_5.keys():\n",
    "        result_string += f\"{explanation_dict_part_5[key]}: {parser_dict[key](key)}\\n\"\n",
    "    \n",
    "    return result_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the OQ data, and intake if found, to a file to send to a therapist to predict on\n",
    "def create_prediction_file(data, save_path):\n",
    "    #data will be a row from sub_df or something like it\n",
    "    #save_path will tell the script the folder to save a file to\n",
    "\n",
    "    with open(save_path, 'w') as file:\n",
    "        #First, write previous OQ scores\n",
    "        file.write(f'Previous OQ scores: ')\n",
    "        string_to_add = \"\"\n",
    "        for val in data['Previous']:\n",
    "            string_to_add += str(int(val)) + \", \"\n",
    "        string_to_add = string_to_add[:-2] + \"\\n\\n\\n\"\n",
    "        file.write(string_to_add)\n",
    "\n",
    "        #If there's intake data, add that too\n",
    "        if data['Session'] in list(master_df_2_test['SessionID']):\n",
    "            try:\n",
    "                assert len(master_df_2_test[master_df_2_test['SessionID']==data['Session']])==1\n",
    "            except:\n",
    "                raise\n",
    "            idx = master_df_2_test[master_df_2_test['SessionID']==data['Session']].index[0]\n",
    "            file.write(detransform_features(master_df_2_test.iloc[idx])+\"\\n\\n\")\n",
    "        file.write(\"Prediction: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the files\n",
    "for therapist_num in range(3):\n",
    "    for row_idx in range(120):\n",
    "        create_prediction_file(sub_df.iloc[therapist_num*num_timeseries_per_therapist + row_idx], f'therapist_{therapist_num}/{row_idx+1}.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data and set up information needed to get therapist predictions from special file structure\n",
    "therapist_match_df = pd.read_csv('data_linking_info.csv')\n",
    "therapist_match_dict = {}\n",
    "for row_idx in range(len(therapist_match_df)):\n",
    "    row = therapist_match_df.iloc[row_idx]\n",
    "    therapist_match_dict[(row['Study Therapist Index'], row['Observation Index']+1)] = (row['Session ID'], row['# of Previous OQs'])\n",
    "    #I hope that works\n",
    "with open('test_data_new.pkl', 'rb') as file:\n",
    "    test_data_df = pickle.Unpickler(file=file).load()\n",
    "\n",
    "subfolder_dict = {}\n",
    "for i in range(1,21):\n",
    "    subfolder_dict[i] = \"1-20\"\n",
    "for i in range(21,41):\n",
    "    subfolder_dict[i] = \"21-40\"\n",
    "for i in range(41,61):\n",
    "    subfolder_dict[i] = \"41-60\"\n",
    "for i in range(61,81):\n",
    "    subfolder_dict[i] = \"61-80\"\n",
    "for i in range(81,101):\n",
    "    subfolder_dict[i] = \"81-100\"\n",
    "for i in range(101,121):\n",
    "    subfolder_dict[i] = \"101-120\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given a session number and how far into it we are, get the real next value\n",
    "def get_true_val(session, num_prev):\n",
    "    sub_df = test_data_df[test_data_df['Session']==session]\n",
    "    ans_rows_list = [sub_df.iloc[i] for i in range(len(sub_df)) if len(sub_df.iloc[i]['Previous'])==num_prev]\n",
    "    assert len(ans_rows_list)==1\n",
    "    return int(ans_rows_list[0]['Next'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function actually gets therapist prediction data out from the specialized files they're in, and gets the real values\n",
    "# (they were returned several different ways)\n",
    "\n",
    "def read_therapist_predictions(folder_name, therapist_idx, mode='text', input_filename='', index_col = 'vignette', data_col = 'predicted OQ'): #therapist_idx is within the study - should be 0, 1, or 2\n",
    "        #filename argument only used if mode==csv\n",
    "    assert mode in ['text', 'csv']\n",
    "    if mode=='csv' and (input_filename=='' or input_filename is None):\n",
    "        raise ValueError(\"Need a specific filename for csv parsing\")\n",
    "    \n",
    "\n",
    "    true_vals = np.zeros(120)\n",
    "    predictions = np.zeros(120)\n",
    "\n",
    "    if mode=='csv':\n",
    "        filename=folder_name+'/'+input_filename\n",
    "        predictions_df = pd.read_csv(filename).set_index(index_col)\n",
    "\n",
    "    for idx in range(1,121):\n",
    "        if mode=='text':\n",
    "            filename = folder_name+'/'+subfolder_dict[idx]+'/'+str(idx)+\".txt\"\n",
    "            with open(filename, 'r') as file:\n",
    "                last_line = file.readlines()[-1]\n",
    "                assert last_line[:11] == \"Prediction:\"\n",
    "                predictions[idx-1] = int(last_line[11:].strip())\n",
    "                session, num_prev = therapist_match_dict[(therapist_idx, idx)]\n",
    "                true_vals[idx-1] = get_true_val(session, num_prev)\n",
    "\n",
    "        elif mode=='csv':\n",
    "            predictions[idx-1] = int(predictions_df.loc[idx][data_col])\n",
    "            session, num_prev = therapist_match_dict[(therapist_idx, idx)]\n",
    "            true_vals[idx-1] = get_true_val(session, num_prev)\n",
    "    return true_vals, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the predictions and true values for therapist 2\n",
    "true_vals_2, predictions_2 = read_therapist_predictions('therapist_2_predictions', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load predictions and true values in the time series for the other therapist, therapist 0\n",
    "true_vals_0, predictions_0 = read_therapist_predictions('therapist_0_predictions',0,'csv','therapist_0_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_errors_0 = np.abs(true_vals_0-predictions_0)\n",
    "abs_errors_2 = np.abs(true_vals_2-predictions_2)\n",
    "abs_errors_pooled = np.concatenate([abs_errors_0, abs_errors_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Therapist 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSE and MAE\n",
    "print(f\"Therapist 0 MSE: {np.mean(abs_errors_0**2)}\")\n",
    "print(f\"Therapist 0 MAE: {np.mean(abs_errors_0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credible interval\n",
    "nonzero_errors_0 = abs_errors_0.copy()\n",
    "nonzero_errors_0[nonzero_errors_0==0]=REPLACE_VAL\n",
    "\n",
    "with pm.Model() as model:\n",
    "    mean = pm.Normal('mean', means_mean, sigma=np.sqrt(means_var))\n",
    "    var = pm.Gamma('var', alpha=vars_a, beta=vars_b)\n",
    "    y = pm.Gamma('absolute error', alpha=mean**2/var, beta=mean/var, observed=nonzero_errors_0)\n",
    "    trace=pm.sample(25000)\n",
    "\n",
    "all_mean_draws = np.concatenate(np.array(trace['posterior']['mean']))\n",
    "cutoff_idx = int(.025*len(all_mean_draws))\n",
    "lower_bound = np.sort(all_mean_draws)[cutoff_idx]\n",
    "upper_bound = np.sort(all_mean_draws)[-cutoff_idx-1]\n",
    "print(f\"{lower_bound}-{upper_bound}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Therapist 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSE and MAE\n",
    "print(f\"Therapist 2 MSE: {np.mean(abs_errors_2**2)}\")\n",
    "print(f\"Therapist 2 MAE: {np.mean(abs_errors_2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credible interval\n",
    "nonzero_errors_2 = abs_errors_2.copy()\n",
    "nonzero_errors_2[nonzero_errors_2==0]=REPLACE_VAL\n",
    "\n",
    "with pm.Model() as model:\n",
    "    mean = pm.Normal('mean', means_mean, sigma=np.sqrt(means_var))\n",
    "    var = pm.Gamma('var', alpha=vars_a, beta=vars_b)\n",
    "    y = pm.Gamma('absolute error', alpha=mean**2/var, beta=mean/var, observed=nonzero_errors_2)\n",
    "    trace=pm.sample(25000)\n",
    "    \n",
    "all_mean_draws = np.concatenate(np.array(trace['posterior']['mean']))\n",
    "cutoff_idx = int(.025*len(all_mean_draws))\n",
    "lower_bound = np.sort(all_mean_draws)[cutoff_idx]\n",
    "upper_bound = np.sort(all_mean_draws)[-cutoff_idx-1]\n",
    "print(f\"{lower_bound}-{upper_bound}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooled therapists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSE and MAE\n",
    "print(f\"Pooled therapist MSE: {np.mean(abs_errors_pooled**2)}\")\n",
    "print(f\"Pooled therapist MAE: {np.mean(abs_errors_pooled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credible interval\n",
    "nonzero_errors_pooled = abs_errors_pooled.copy()\n",
    "nonzero_errors_pooled[nonzero_errors_pooled==0]=REPLACE_VAL\n",
    "\n",
    "with pm.Model() as model:\n",
    "    mean = pm.Normal('mean', means_mean, sigma=np.sqrt(means_var))\n",
    "    var = pm.Gamma('var', alpha=vars_a, beta=vars_b)\n",
    "    y = pm.Gamma('absolute error', alpha=mean**2/var, beta=mean/var, observed=nonzero_errors_pooled)\n",
    "    trace=pm.sample(25000)\n",
    "    \n",
    "all_mean_draws = np.concatenate(np.array(trace['posterior']['mean']))\n",
    "cutoff_idx = int(.025*len(all_mean_draws))\n",
    "lower_bound = np.sort(all_mean_draws)[cutoff_idx]\n",
    "upper_bound = np.sort(all_mean_draws)[-cutoff_idx-1]\n",
    "print(f\"{lower_bound}-{upper_bound}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the code relating to LSTMs was performed though a high-performance computing service using shell scripts and a command-line interface. The necessary files to reproduce the process are in this repo; The process is followed by running the following commands, in order, in an appropriate environment. Note that some files have placeholder names instead of real folders, virtual environments, etc.\n",
    "#TODO Add what's in the environment\n",
    "\n",
    "1. python create_config_files.py\n",
    "1. sbatch gridsearch_new_cleaning.sh\n",
    "1. Use the notebook parse_gridsearch_outputs.ipynb to determine the hyperparameters, and enter them into new_cleaning_training.py\n",
    "1. sbatch train_new_cleaning.sh\n",
    "1. Select the saved model with the best validation-set accuracy out of placeholder folder 3 and save it somewhere accessible to this notebook, then use the below cells to get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PLACEHOLDER_FOLDER_3_or_4/path/to/best/model', 'rb') as file:\n",
    "        model = torch.load(file, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best model's df_width\n",
    "MODEL_WIDTH = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_labels = make_data_rectangular(test_OQ_list_new, df_width = MODEL_WIDTH, impute_val=overall_mean_OQ_train)\n",
    "\n",
    "X_test, y_test = torch.tensor(test_data).float().unsqueeze(2), torch.tensor(test_labels).float().unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "y_pred = model(X_test)[:,-1,:].unsqueeze(1)\n",
    "abs_errors = np.abs(np.array(y_test).squeeze()-np.array(y_pred.detach().squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE: {np.mean(abs_errors**2)}\")\n",
    "print(f\"MAE: {np.mean(abs_errors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_errors = abs_errors.copy()\n",
    "nonzero_errors[nonzero_errors==0]=REPLACE_VAL\n",
    "\n",
    "with pm.Model() as model:\n",
    "    mean = pm.Normal('mean', means_mean, sigma=np.sqrt(means_var))\n",
    "    var = pm.Gamma('var', alpha=vars_a, beta=vars_b)\n",
    "    y = pm.Gamma('absolute error', alpha=mean**2/var, beta=mean/var, observed=nonzero_errors)\n",
    "    trace=pm.sample(25000)\n",
    "    \n",
    "all_mean_draws = np.concatenate(np.array(trace['posterior']['mean']))\n",
    "cutoff_idx = int(.025*len(all_mean_draws))\n",
    "lower_bound = np.sort(all_mean_draws)[cutoff_idx]\n",
    "upper_bound = np.sort(all_mean_draws)[-cutoff_idx-1]\n",
    "print(f\"{lower_bound}-{upper_bound}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CAPS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
